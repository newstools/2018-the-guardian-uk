An autonomous Uber car killed a woman in the street in Arizona, police said, in what appears to be the first reported fatal crash involving a self-driving vehicle and a pedestrian in the US. Tempe police said the self-driving car was in autonomous mode at the time of the crash and that the vehicle hit a woman, who was walking outside of the crosswalk and later died at a hospital. There was a vehicle operator inside the car at the time of the crash. Uber said in a statement on Twitter: “Our hearts go out to the victim’s family. We are fully cooperating with local authorities in their investigation of this incident.” A spokesman declined to comment further on the crash. The company said it was pausing its self-driving car operations in Phoenix, Pittsburgh, San Francisco and Toronto. Dara Khosrowshahi, Uber’s CEO, tweeted: “Some incredibly sad news out of Arizona. We’re thinking of the victim’s family as we work with local law enforcement to understand what happened.” Uber has been testing its self-driving cars in numerous states and temporarily suspended its vehicles in Arizona last year after a crash involving one of its vehicles, a Volvo SUV. When the company first began testing its self-driving cars in California in 2016, the vehicles were caught running red lights, leading to a high-profile dispute between state regulators and the San Francisco-based corporation. Police identified the victim as 49-year-old Elaine Herzberg and said she was walking outside of the crosswalk with a bicycle when she was hit at around 10pm on Sunday. Images from the scene showed a damaged bike. The 2017 Volvo SUV was traveling at roughly 40 miles an hour, and it did not appear that the car slowed down as it approached the woman, said Tempe sergeant Ronald Elcock. Elcock said he had watched footage of the collision, which has not been released to the public. He also identified the operator of the car as Rafael Vasquez, 44, and said he was cooperative and there were no signs of impairment. The self-driving technology is supposed to detect pedestrians, cyclists and others and prevent crashes. John M Simpson, privacy and technology project director with Consumer Watchdog, said the collision highlighted the need for tighter regulations of the nascent technology. “The robot cars cannot accurately predict human behavior, and the real problem comes in the interaction between humans and the robot vehicles,” said Simpson, whose advocacy group called for a national moratorium on autonomous car testing in the wake of the deadly collision. Simpson said he was unaware of any previous fatal crashes involving an autonomous vehicle and a pedestrian. Tesla Motors was the first to disclose a death involving a self-driving car in 2016 when the sensors of a Model S driving in autopilot mode failed to detect a large white 18-wheel truck and trailer crossing the highway. The car drove full speed under the trailer, causing the collision that killed the 40-year-old behind the wheel in the Tesla. Earlier this year, California regulators approved the testing of self-driving cars on public roads without human drivers monitoring inside. “The technology is not ready for it yet, and this just sadly proves it,” said Simpson. In one recent incident, California police officers found a Tesla that was stopped in the middle of a five-lane highway and found a driver asleep behind the wheel. The man said the vehicle was in “autopilot”, which is Tesla’s semi-autonomous driver assist system, and he was arrested on suspicion of drunk driving. In another recent case, a Tesla car rear-ended a fire truck on a freeway, with the driver again telling the authorities the car was in autopilot mode at the time of the collision. Michael G Bennett, an Arizona State University associate research professor who studies autonomous cars, said the self-driving vehicles have become ubiquitous around campus and on the streets in Tempe. Often they have operators behind the wheels, but sometimes they are fully autonomous with no human inside. The fatal collision could spark significant calls for reform and reflections within the industry, he said. “It may be problematic for the industry, because one of their central arguments for the value of the technology is that it is superior to human drivers,” said Bennett, adding that autonomous cars should be able to detect pedestrians and avoid hitting them, even if they aren’t in crosswalks: “Every day, pedestrians in cities around the world step outside of the crosswalk.” The governor of Arizona, Doug Ducey, has been a strong proponent of allowing corporations to test the technology in his state, publicly slamming other governments for “over regulation” and in 2016 urging Uber to “ditch California” and launch in his region. In March, he issued new rules and said that more than 600 automated vehicles have driven on public roads in the state. “Our prayers are with the victim, and our hearts go out to her family,” Patrick Ptak, Ducey’s spokesman, said in an email to the Guardian, adding, “Public safety is our top priority.” Linda Bailey, the executive director of the National Association of City Transportation Officials (Nacto), said in an interview that there has not been enough regulatory oversight of testing and that some governments are overwhelmed trying to understand autonomous technology and its limitations. “There’s an essential role for the public sector in regulating the safety of these vehicles, which has been largely left to private companies,” she said, adding that Nacto supports third-party testing of the vehicles. Tempe’s mayor, Mark Mitchell, defended the city’s ongoing support of autonomous vehicles in a statement Monday, saying: “All indications we had in the past show that traffic laws are being obeyed by the companies testing here.”