Like all everyday miracles of technology, the longer you watch a robot perform surgery on a human being, the more it begins to look like an inevitable natural wonder. Earlier this month I was in an operating theatre at University College Hospital in central London watching a 59-year-old man from Potters Bar having his cancerous prostate gland removed by the four dexterous metal arms of an American-made machine, in what is likely a glimpse of the future of most surgical procedures. The robot was being controlled by Greg Shaw, a consultant urologist and surgeon sitting in the far corner of the room with his head under the black hood of a 3D monitor, like a Victorian wedding photographer. Shaw was directing the arms of the remote surgical tool with a fluid mixture of joystick control and foot-pedal pressure and amplified instruction to his theatre team standing at the patient’s side. The surgeon, 43, has performed 500 such procedures, which are particularly useful for pelvic operations; those, he says, in which you are otherwise “looking down a deep, dark hole with a flashlight”. The first part of the process has been to “dock the cart on to the human”. After that, three surgical tools and a video camera, each on the end of a 30cm probe, have been inserted through small incisions in the patient’s abdomen. Over the course of an hour or more Shaw then talks me through his actions. “I’m just going to clip his vas deferens now,” he says, and I involuntarily wince a little as a tiny robot pincer hand, magnified 10 times on screens around the operating theatre, comes into view to permanently cut off sperm supply. “Now I’m trying to find that sweet spot where the bladder joins the prostate,” Shaw says, as a blunt probe gently strokes aside blood vessels and finds its way across the surface of the plump organ on the screen, with very human delicacy. After that, a mesmerising rhythm develops of clip and cauterise and cut as the velociraptor pairing of “monopolar curved scissors” and “fenestrated bipolar forceps” is worked in tandem – the surprisingly exaggerated movements of Shaw’s hands and arms separating and sealing tiny blood vessels and crimson connective tissue deep within the patient’s pelvis 10ft away. In this fashion, slowly, the opaque walnut of the prostate emerges on screen through tiny plumes of smoke from the cauterising process. This operation is part of a clinical trial of a procedure pioneered in German hospitals that aims to preserve the fine architecture of microscopic nerves around the prostate – and with them the patient’s sexual function. With the patient still under anaesthetic, the prostate, bagged up internally and removed, will be frozen and couriered to a lab at the main hospital site a mile away to determine if cancer exists at its edges. If it does, it may be necessary for Shaw to cut away some of these critical nerves to make sure all trace of malignancy is removed. If no cancer is found at the prostate’s margins the nerves can be saved. While the prostate is dispatched across town, Shaw uses a minuscule fish hook on a robot arm to deftly sew bladder to urethra. The Da Vinci robot that Shaw is using for this operation, made by the American firm Intuitive Surgical, is about as “cutting edge” as robotic health currently gets. The £1.5m machine enables the UCH team to do 600 prostate operations a year, a four-fold increase on previous, less precise, manual laparoscopic techniques. Mostly, Shaw does three operations one or two days a week, but there have been times, with colleagues absent, when he has done five or six days straight. “If you tried to do that with old-fashioned pelvic surgery, craning over the patient, you would be really hurting, your shoulders and your back would seize up,” he says. There are other collateral advantages of the technology. It lends itself to accelerated and effective training both because it retains a 3D film of all the operations conducted, and enables a virtual-reality suite to be plugged in – like learning to fly a plane using a simulator. The most important benefit however is the greater safety and fewer complications the robot delivers. I wonder if it changes the psychological relationship between surgeon and patient, that palpable intimacy. Shaw does not believe so. “The technique itself feels like driving,” he says. “But that 3D vision is very immersive. You are getting lots of information and very little distraction and you are seeing inside the patient from 2cm away.” There are, he says, still diehards doing prostatectomies as open surgery, but he finds it hard to believe that their patients are fully informed about the alternatives. “Most people come in these days asking for the robot.” If a report published this month on the future of the NHS is anything to go by, it is likely that “asking for the robot” could increasingly be the norm in hospitals. The interim findings of the Institute for Public Policy Research’s long-term inquiry into the future of health – led by Lord Darzi, the distinguished surgeon and former minister in Gordon Brown’s government – projected that many functions traditionally performed by doctors and nurses could be supplanted by technology. “Bedside robots,” the report suggested, may soon be employed to help feed patients and move them between wards, while “rehabilitation robots” would assist with physiotherapy after surgery. The centuries-old hands-on relationship between doctor and patient would inevitably change. “Telemedicine” would monitor vital signs and chronic conditions remotely; online consultations would be routine, and someone arriving at A&E “may begin by undergoing digital triage in an automated assessment suite”. Even the consultant’s accumulated wisdom will be superseded. Machine-learning algorithms fed with “big data” would soon be employed to “make more accurate diagnoses of diseases such as pneumonia, breast and skin cancers, eye diseases and heart conditions”. By embracing a process to achieve “full automation” Lord Darzi’s report projects that £12.5bn a year worth of NHS staff time (£250m a week) would be saved “for them to spend interacting with patients” – a belief that sounds like it would be best written on the side of a bus. While some of these projections may sound far more than the imagined decade away, others are already a reality. Increasingly, the data from sensors and implants measuring blood sugars and heart rhythms is collected and fed directly to remote monitors; in London, the controversial pilot scheme GP@Hand has seen more than 40,000 people take the first steps toward a “digital health interface” by signing up for online consultations accessed through an app – and in the process, de-registering from their bricks-and-mortar GP surgery. Meanwhile, at the sharpest end of healthcare – in the operating theatre – robotic systems like the one used by Greg Shaw are already proving the report’s prediction that machines will carry out surgeries with greater dexterity than humans. As a pioneer of robotic surgical techniques, Lord Darzi knows this better than most. Bedside robots will feed patients while others would assist with physio In a way, it is surprising that it has taken so long to reach this point. Hands-off surgery was first developed by the US military at the end of the last century. In the 1990s the Pentagon wanted to explore ways in which operations at M*A*S*H-style field hospitals might be performed by robots controlled by surgeons at a safe distance from the battlefield. Their investment in Intuitive Surgical and its Da Vinci prototype has given the Californian company – valued at $62bn – a virtual monopoly, fiercely guarded, with 4,000 robots now operating around the world. Jaime Wong MD is the consultant lead on the R&D programme at Intuitive Surgical. He is also a urologist who has been using a Da Vinci robot for more than a decade and watched it evolve from original 2D displays that involved more spatial guesswork, to the current far more manoeuvrable and all-seeing version. Wong still enjoys seeing traditional open surgeons witnessing a robotic operation for the first time and “watching the amazement on their faces at all the things they did not quite realise are located in that area”. In the next stage of development, he sees artificial intelligence (AI) and machine learning playing a significant role in the techniques. “Surgery is becoming digitised, from imaging to movement to sensors,” he says, “and everything is translating into data. The systems have a tremendous amount of computational power and we have been looking at segmenting procedures. We believe, for example, we can use these processes to reduce or eliminate inadvertent injuries.” Up until recently, Da Vinci, having stolen a march on any competition, has had this field virtually to itself. In the coming year, that is about to change. Google has, inevitably, developed a competitor (with Johnson & Johnson) called Verb. The digital surgery platform – which promises to “combine the power of robotics, advanced instrumentation, enhanced visualisation, connectivity and data analytics” – aims to “democratise surgery” by bringing the proportion of robot-assisted surgeries from the current 5% up to 75%. In Britain, meanwhile, a 200-strong company called Cambridge Medical Robotics is close to approval for its pioneering system, Versius, which it hopes to launch this year. Wong says he welcomes the competition: “I tend to think it validates what we have been doing for two decades.” The latest creators of robot surgeons see ways to move the technology into new areas. Martin Frost, CEO of the Cambridge company, tells me how the development of Versius has involved the input of hundreds of surgeons with different soft-tissue specialities, to create a portable and modular system that could operate not just in pelvic areas but in more inaccessible parts of the head, neck and chest. “Every operating room in the world currently possesses one essential component, which is the surgeons’ arm and hand,” Frost says. “We have taken all of the advantages of that form to make something that is not only bio-mimicking but bio-enhancing.” The argument for the superiority of minimally invasive surgery is pretty much won, Frost suggests: “The robotic genie is out of the bottle.” And what about that next stage – does Frost see a future in which AI-driven techniques are involved in the operation itself? “We see it in small steps,” he says. “We think that it is possible, within a few years, that a robot may do part of certain procedures ‘itself’, but we are obviously a very long way from a machine doing diagnosis and cure, and there being no human involved.” A specialist mentor could be looking at different camera views, providing second opinions. It will be like ‘phone a friend’ The other holy grail of telesurgery – the possibility of remote “battlefield” operations – is closer to being a reality. In a celebrated instance, Dr Jacques Marescaux, a surgeon in Manhattan, used a protected high-speed connection and remote controls to successfully remove the gallbladder of a patient 3,800 miles away in Strasbourg in 2001. Since then there have been isolated instances of other remote operations but no regular programme. In 2011, the US military funded a five-year research project to determine how feasible such a programme might be with existing technology. It was led by Dr Roger Smith at the Nicholson Center for advanced surgery in Florida. Smith explained to me how his study was primarily to determine two things: first, latency – the tiny time lag of high-speed connections over large distances – and second, how that lag interfered with a surgeon’s movements. His studies found that if the lag rose above 250 milliseconds “the surgeon begins to see or sense that something is not quite right”. But also that using existing data connections, between major cities, or at least between major hospital systems, “the latency was always well below what a human surgeon could perceive”. The problem lay in the risk of unreliability of the connection. “We all live on the internet,” Smith says. “Most of the time your internet connection is fantastic. Just occasionally your data slows to a crawl. The issue is you don’t know when that will happen. If it occurs during a surgery you are in trouble.” No surgeon – or patient – would like to see a buffering symbol on their screen. The ways around that would involve dedicated networks – five lines of connectivity with a performance level at least two times what you would ever need, Smith says, “so that the chances of having an issue were like one in a million”. Those kinds of connections are available, but the lack of investment is more one of regulation and liability than cost. Who would bear the risk of connection failure? The state in which the surgeon was located, or that in which the patient was anaesthetised – or the countries through which the cable passed? As a result, Smith says: “In the civilian world, there are few situations where you would say this is a must-have thing.” He envisages three possible champions of telesurgery: the military, “If you could, say, create a connection where the surgeon could be in Italy and the patient in Iraq”; medical missionaries, “Where surgeons in the developed world worked through robots in places without advanced surgeons”; and Nasa, “At a point where you have enough people in space that you need to set up a way to do surgery.” For the time being the technology is not robust enough for any of these three. For Jaime Wong the risks are likely to remain too great. Intuitive Surgical is pursuing the concepts of “telementoring” or “teleproctoring” rather than telesurgery. “The local surgeon would be performing the surgery, while our monitor would be remote,” he suggests, “and a specialist mentor could be looking at different camera views, providing second opinions. It will be like ‘phone a friend’.” True telesurgery, Roger Smith suggests, also begs a further question, one which we may yet hear in the coming decade or so. “Would you have an operation without a surgeon in the room?” For the time being, the answer remains a no-brainer.