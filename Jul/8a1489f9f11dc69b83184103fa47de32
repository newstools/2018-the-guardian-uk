If you’re not on Twitter, don’t start. It’s like smoking: highly addictive and no good will come of it. But if you are, log on and put “Elon Musk” in your handle. Twitter has had enough of fraudulent Musk imitators and has decided to put a stop to their merry japes. Your account will be immediately blocked until you’ve proved you’re a real person (which you do via a text to your phone). So there is no reason at all why Twitter couldn’t deal with hate speech, disruptive bots or Russian troll factories: all they’d need is a few Nazi keywords, a flag on anyone with a name like @GREATBRITISHSTEVE2876776, a quick Musk-style block and an identity check. There are anxieties, of course, around fixes that come from the social media platforms themselves. This leaves political and moral adjudication to tech giants, whose only known skill is virtual domination. The likes of Mark Zuckerberg have no obvious competencies in ethics. But they could start really simply, by ejecting known racists and troll accounts. Sure, it’s a wide net that could easily ensnare the president of the United States, and who knows what mischief he’d be up to if he weren’t on Twitter. They could move on to the more generalised groups that simply sow bitter hatred and division with misinformation, those whom the Indian press recently called “mischief mongers”. We could gradually build an ethical code collectively, and make it so much more sophisticated than just flagging up swearwords but having an open-door policy on rape threats. Crucially, it’s not that hard: this is how civilisations are built and decency is maintained, by making trenchant decisions about what’s acceptable and what isn’t, not by endless equivalising between one person’s right to say whatever they want, and another’s right to a functional democracy. The MPs on the digital, culture, media and sport select committee have rightly been lauded across the world for their pluck and rigour in investigating “fake news”, dark ads and data abuse. If electoral meddling by a foreign power is wrong, its full extent has to be scoped. It cannot be filed under “modern, hyper-connected world”, along with Fortnite and eBay. Yet the committee’s characterisation of the internet as the “wild west”, along with some of its prescriptions – a micro “education” tax on Facebook et al, to be spent on telling 12-year-olds not to believe everything they read – plays into the narrative of our mutual helplessness. It implies that, since there’s nothing to be done about the spread of disinformation, we must all, individually, become better at recognising it for what it is. This approach – promulgated most consistently by Zuckerberg himself – is remarkable for its slacker fatalism. Zuckerberg explained recently that Facebook couldn’t take down posts that deny the Holocaust because “there are things that different people get wrong … I don’t think that they’re intentionally getting it wrong, but I think it’s hard to impugn intent and to understand the intent.” Until you can see into the mind of the person who insists that Auschwitz didn’t exist, you can’t impugn them. They may simply be mistaken. The proposition asks us to believe in a group of people who dispute a historical truth by mistake, who mean nothing by it and have no darker purpose in spreading it. We can recognise this studied impotence from other sectors, notably finance: there’s nothing to be done with the territory, because it is just too vast. How can I know the intentions of a billion users? And if we can’t control it, what can a state regulator, with a fraction of the money and a zillionth of the expertise, possibly achieve? It has been established as an unchallengeable status, to be too big to fail – charged with your failures, you simply insist upon your impossible bigness. A glance at Wikipedia is enough to expose the fallacy in this argument: it is within the bounds of human ingenuity to create online spaces defined by cooperation not discord, expertise not falsity, great reservoirs of shared knowledge. The civic tech entrepreneur Ed Saperia, who set up Newspeak House, a “community space for political technologists”, is supporting the work of PhD student Sophie Chesney in developing an algorithm for the detection of fake news. Explaain.com scans the content you’re reading and automatically links it to pop-up cards that check its veracity. Meanwhile a score of developers are mobilising from different angles against the spread of sheer mendacity that has plagued elections from here to the US, Canada to Nigeria. A flawed vision of online political activity is emerging. This world is seen as an inherently lawless place, where bad messages and big money can be funnelled into the web’s dark corners where no respectable person can see them. This is treated as an inevitability, boastfully by disruptors, ruefully by social media giants. So we arrive at the logical endpoint of free market fundamentalism. A social space that can’t be regulated, yet affects everything from voting to consuming; which obviates regulation altogether, while disempowering the individual by blaming them for failures of credulousness. The only flaw in this analysis is that we are not powerless. We have the same moral musculature we’ve always had. We are all agents in both analogue and digital terrains, and enough of us (not me) are ingenious in ways that snake-oil blowhards threatening an invasion of Turkish immigrants couldn’t begin to imagine. We are more than capable of fighting back. • Zoe Williams is a Guardian columnist