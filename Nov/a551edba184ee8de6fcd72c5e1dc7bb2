In 1965, the mathematician I J “Jack” Good, one of Alan Turing’s code-breaking colleagues during the second world war, started to think about the implications of what he called an “ultra-intelligent” machine – ie “a machine that can surpass all the intellectual activities of any man, however clever”. If we were able to create such a machine, he mused, it would be “the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control”. Note the proviso. Good’s speculation has lingered long in our collective subconscious, occasionally giving rise to outbreaks of fevered speculation. These generally focus on two questions. How long will it take us to create superintelligent machines? And what will it be like for humans to live with – or under – such machines? Will they rapidly conclude that people are a waste of space? Does the superintelligent machine pose an existential risk for humanity? The interesting thing about tech companies is that, until recently, we failed to notice that they were just corporations The answer to the first question can be summarised as “longer than you think”. And as for the second question, well, nobody really knows. How could they? Surely we’d need to build the machines first and then we’d find out. Actually, that’s not quite right. It just so happens that history has provided us with some useful insights into what it’s like to live with – and under – superintelligent machines. They’re called corporations, and they’ve been around for a very long time – since about 1600, in fact. Although they are powered by human beings, they are in fact nonhuman entities to which our legal systems grant the status of legal personhood. We can therefore regard them as artificial superintelligences because they possess formidable capacities for rational behaviour, reasoning, perception and action. And they have free will: they can engage in purposeful behaviour aimed at achieving self-determined goals. They possess and deploy massive resources of financial capital and human expertise. And they are, in principle at least, immortal: they can have life spans that greatly exceed those of humans, and some are capable of surviving catastrophes that kill millions of people. Just think of how many of the big German corporations of the 1930s – companies such as Thyssen, BASF, Mercedes, Siemens, Bosch, Volkswagen – are still prospering today. So if corporations are the superintelligences de nos jours, what can that tell us about living with superintelligent machines? On the positive side, such entities are capable of accomplishing astonishing things – from building a new city, road or rail network, to indexing the world wide web, connecting 2.24 billion people, scanning all the world’s books, launching heavy rockets into space (and bringing them back safely), etc. But these superintelligent entities have other characteristics too. The most disturbing one is that they are intrinsically sociopathic – they are AIs that stand apart from the rest of society, existing for themselves and only for themselves, caring nothing for the norms and rules of society, and obeying only the letter (as distinct from the spirit) of the law. That doesn’t means that corporations do not regularly dissemble, or proclaim their “corporate social responsibility”, ethical standards, environmental awareness or the “values” that are implicit in their brands. They do. For the most part, though, this is just cant, designed to burnish the public image of the corporation. Artificial Intelligence has various definitions, but in general it means a program that uses data to build a model of some aspect of the world. This model is then used to make informed decisions and predictions about future events. The technology is used widely, to provide speech and face recognition, language translation, and personal recommendations on music, film and shopping sites. In the future, it could deliver driverless cars, smart personal assistants, and intelligent energy grids. AI has the potential to make organisations more effective and efficient, but the technology raises serious issues of ethics, governance, privacy and law. The interesting thing about the tech companies is that, until recently, we failed to notice that they were just corporations too. At the beginning, we were entranced by their young founders with their open-eyed “missions” to avoid being evil, enable people to broadcast themselves, connect the world, organise its information and build global communities. We were likewise seduced by their colourful, playful workplaces, free gourmet food, on-site massages and prevailingly hipster ethos, so didn’t notice that under all that gloss there lurked ruthless capitalist machines intent on harvesting as much data on our daily existence as they could. Fortunately, after two years of scandals, the scales are now beginning to fall from our eyes and we are seeing these outfits for what they are: mere corporations. Anyone who has been on the receiving end of a tech company’s rage – as this newspaper was on the Friday night that we broke the Cambridge Analytica story – would be hard put to say what is the difference between Facebook and, say, a tobacco company whose cover had been blown. Which is why the recent revelations by the New York Times that Facebook had been employing a slimy PR firm to discredit the company’s critics by linking them to George Soros – a long-time target of antisemitic conspiracy theories – no longer came as a shock. When you’re a sociopathic corporation, the ends always justify the means. So the challenge we will one day face is whether we can design superintelligent machines that are better behaved. Brain on a stickThe website New Atlas reports on the commodification of machine-learning technology. Intel is now selling a plug-in neural network on a USB stick. Where’s the beef?“I Found the Best Burger Place in America. And Then I Killed It”. Intriguing Thrillist essay by Kevin Alexander. I hear where you’re coming from…The Intercept reports that Amazon has a patent for recognising accents. Good news for spooks. Less good for privacy.