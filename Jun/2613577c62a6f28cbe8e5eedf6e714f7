The idea of killer robots rising up and destroying humans is a Hollywood fantasy and a distraction from the more pressing dilemmas that intelligent machines present to society, according to one of Britain’s most influential computer scientists. Sir Nigel Shadbolt, professor of computer science at the University of Oxford, predicts that AI will bring overwhelming benefits to humanity, revolutionising cancer diagnosis and treatment, and transforming education and the workplace. If problems arise, he said, it will not be because sentient machines have unexpectedly gone rogue in a Terminator-like scenario. “The danger is clearly not that robots will decide to put us away and have a robot revolution,” he said. “If there [are] killer robots, it will be because we’ve been stupid enough to give it the instructions or software for it to do that without having a human in the loop deciding.” Prof Shadbolt made the comments ahead of a talk at the CogX conference in London on Monday, at which a number of leading figures are presenting on the latest developments in AI and their potential impact. Jürgen Schmidhuber, a German computer scientist and a pioneer of modern machine learning, was also dismissive of the idea that the dawn of AI could result in doom for humankind. “The entertainment industry is powerful at planting these ideas in your heads, but actually the plots in these movies are really silly,” he said. Schmidhuber, who runs the AI company Nnaisense, based in Lugano, Switzerland and who is also speaking at CogX on Monday, cited “intense commercial pressure” towards companies making human-friendly AI. “95% of all AI research is all about making human lives longer, healthier and happier,” he said. “They want to sell you something that you want to buy.” Previously, Elon Musk, CEO of Tesla and an early investor in Google DeepMind, warned that intelligent machines pose an existential threat to humanity. Concerns have also been raised that autonomous machines could leave huge numbers of people without jobs and create huge wealth inequalities. However, Prof Shadbolt is optimistic about the social and economic impact of emerging technologies such as machine learning, in which computer programmes learn tasks by looking for patterns in huge datasets. A central goal of the field of artificial intelligence is for machines to be able to learn how to perform tasks and make decisions independently, rather than being explicitly programmed with inflexible rules. There are different ways of achieving this in practice, but some of the most striking recent advances, such as AlphaGo, have used a strategy called reinforcement learning. Typically the machine will have a goal, such as translating a sentence from English to French and a massive dataset to train on. It starts off just making a stab at the task – in the translation example it would start by producing garbled nonsense and comparing its attempts against existing translations. The program is then “rewarded” with a score when it is successful. After each iteration of the task it improves and after a vast number of reruns, such programs can match and even exceed the level of human translators. Getting machines to learn less well defined tasks or ones for which no digital datasets exist is a future goal that would require a more general form of intelligence, akin to common sense. “I don’t see it destroying jobs grim reaper style,” he said. “People are really inventive at creating new things for humans to do for which will pay them a wage. Leisure, travel, social care, cultural heritage, even reality TV shows. People want people around them and interacting with them.” Similarly, Shadbolt suggested, the prospect of humans developing emotional bonds with machines was not entirely uncharted territory. “We’ll embue [robots] with lots of human qualities, we will begin to empathise with them” he said. “That doesn’t require these systems to be self-aware. You anthropomorphise your goldfish at home. I certainly did that with a teddy bear when I was a child.” However, he acknowledged that latest advances in AI, which include the ability to not only interpret photos and videos but to artificially generate this material, raised “uncomfortable” new possibilities. “A bereaved widow [could] decide to keep her husband’s voice around on her Alexa,” he said. “There’ll be the digital posthumous voice and character of a loved one. That is going to happen. These systems won’t just be faded photos they’ll be capable of creating new conversations.” Shadbolt said it was essential that the public engaged in discussions about the ethics of how AI is applied, including the need for transparency around how machines make decisions and of how personal data, including medical records, are used. Companies have already participated in a number of collaborations with the NHS in order to train algorithms to perform diagnosis, to stream-line hospital processes or to develop programmes that can identify patients at risk. Schmidhuber said that the advantages of making medical data available are huge and will be necessary to create “super-human artificial doctors”. However, he warned that public health services ought to be protecting the commercial value of patient data. “Many hospitals don’t even know that they’re sitting on a treasure,” he said. “It may be that some hospitals are naive and don’t realise how valuable some of this stuff might be to large IT companies that are thousands of miles aways. If i were running the NHS i would take steps to establish a market where it becomes clear what is the value of this data.”