As our dependence on technology builds and the privacy-destroying, brain-hacking consequences of that start to come to light, we are seeing the return of a science-fiction trope: the rise of the robots. A new wave of television shows, films and video games is grappling with the question of what will happen if we develop the technology to create machines in our own image. Westworld posits that if we could develop realistic androids, we would want to rape and murder them for fun. In Blade Runner 2049, they have replaced humans as sex workers and manual labourers. In the recently released video game Detroit: Become Human, androids are nannies, carers and even pop stars, omnipresent in the home and in city life. The current wave of android fiction centres on what happens when the line between human and machine becomes blurred. At what point do robots deserve rights: when they reach a certain level of intelligence, or when they develop the capacity for emotion, creativity or free will? In the cold war, when we believed that machines might kill us any minute in the shape of nuclear bombs, our nightmare robots were relentless killing machines such as The Terminator or RoboCop – or the pitiless military droids that hunt down the last remnants of humanity in Metalhead, a recent episode of Black Mirror. Now that technology has enmeshed itself in our lives, it is dawning on us that machines can take over in another way – by encroaching on our humanity. Just a few weeks ago, Google demonstrated that its home-assistant robot is capable of holding an unsettlingly natural conversation with a human being over the phone to book a haircut or make a restaurant reservation, complete with “ums” and “ahs” to make the listener believe they are talking to a real person. We are increasingly worried about what will happen if machines become just like us. Adam Williams, lead writer on the game Detroit: Become Human, thinks that the development of human-like emotion is more unsettling than the idea of straightforward robot antagonism. “It’s a more subtle threat to the sanctity of the human category,” he says. “Emotion is something we reserve for ourselves: depth of feeling is what we use to justify the primacy of human life. If a machine is capable of feeling, that doesn’t make it dangerous in a Terminator-esque fashion, but in the abstract sense of impinging on what we think of as classically human.” In the game, household androids that have been mistreated by humans start rebelling, eventually banding together to demand rights. It is not an original premise, but video games now look so lifelike that it is a good litmus test for how comfortable you feel with the idea of a human-like android. The game’s characters, played by human actors, look almost indistinguishably close to real people. Anouk van Maris, a robot cognition specialist who is researching ethical human-robot interaction, has found that comfort levels with robots vary greatly depending on location and culture. “It depends on what you expect from it. Some people love it, others want to run away as soon as it starts moving,” she says. “The advantage of a robot that looks human-like is that people feel more comfortable with it being close to them, and it is easier to communicate with it. The big disadvantage is that you expect it to be able to do human things and it often can’t.” In Japan, where the animus belief perhaps makes people more comfortable with the idea that spirit can reside in something that isn’t human, robots are already being used as shop assistants, in care homes and in schools. Japan is the world leader in robotics and demand is high for robots that could help fill a shortfall in nursing care. The country is home to the creepy Erica, the most realistic female humanoid in existence, and Gatebox AI’s Azuma, a holographic girl in a jar that combines Alexa-like home-assistant functionality with a cute anime look and a simulated, deferential personality. In Europe, by contrast, people are generally uncomfortable with the idea of an android performing roles that require interaction with humans. “In one study, people were asked if there was a robot interacting with children, whether it would be ethically acceptable if the children got attached to that robot,” says Van Maris. “Only 40% thought that was acceptable.” It is telling that US companies design their home-assistant robots to look like black boxes and sound like computers. “A machine can exhibit human-like qualities and not be considered particularly controversial if it doesn’t look human,” says Williams. “That’s what is intriguing. What scares people about that Google Assistant phone call is that it sounds human. The fact that it can construct the conversation is not what scares people – it’s the fact they can’t distinguish it from a real person.” Some robotics experts, including the University of Edinburgh’s Robert Fisher, see the concept of human-like robots as ill-advised. “I don’t think artificial intelligence will ever be like humans,” Fisher says. “We put ourselves and them in a difficult situation by trying to pretend they are human, or make them look like us. Maybe it is better not to do that in the first place. Sex robots is perhaps the only case where there is a reason for them to look human.” On the evidence of Westworld, Detroit: Become Human and Ex Machina – none of which paint the most optimistic portrait of human-android relations – perhaps we will all be better off if our future robot assistants are more Wall-E or R2-D2 in Star Wars than Star Trek’s Data or Blade Runner’s Pris.