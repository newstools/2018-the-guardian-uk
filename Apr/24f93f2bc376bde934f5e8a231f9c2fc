Facebook’s chief executive, Mark Zuckerberg, faced US Congress for the first time on Tuesday over the data sharing scandal. Zuckerberg answered questions from the Senate commerce and judiciary committees on privacy, data mining, regulations and Cambridge Analytica during the course of the marathon five-hour hearing. Here are the key moments: Right to privacy “I believe it’s important to tell people exactly how the information that they share on Facebook is going to be used. “That’s why, every single time you go to share something on Facebook, whether it’s a photo in Facebook, or a message, every single time, there’s a control right there about who you’re going to be sharing it with ... and you can change that and control that in line. “To your broader point about the privacy policy ... long privacy policies are very confusing. And if you make it long and spell out all the detail, then you’re probably going to reduce the per cent of people who read it and make it accessible to them.” His own privacy Senator Dick Durbin asked if Zuckerberg would be comfortable sharing the name of the hotel he stayed in last night. “No. I would probably not choose to do that publicly, here” he said. “I think everyone should have control over how their information is used.” Cambridge Analytica “Cambridge Analytica wasn’t using our services in 2015, as far as we can tell ... They weren’t an advertiser. They weren’t running pages. So we actually had nothing to ban.” Later Zuckerberg corrected himself. “I want to correct one thing that I said earlier in response to a question … [on] why we didn’t ban Cambridge Analytica at the time when we learned about them in 2015. “[From] what my understanding was ... they were not on the platform, [they] were not an app developer or advertiser. When I went back and met with my team afterwards, they let me know that Cambridge Analytica actually did start as an advertiser later in 2015. “So we could have in theory banned them then. We made a mistake by not doing so. But I just wanted to make sure that I updated that because I ... I ... I misspoke, or got that wrong earlier. “When we heard back from Cambridge Analytica that they had told us that they weren’t using the data and deleted it, we considered it a closed case. In retrospect, that was clearly a mistake. We shouldn’t have taken their word for it. We’ve updated our policy to make sure we don’t make that mistake again.” Storing and selling personal data “Yes, we store data ... some of that content with people’s permission.” “There’s a very common misconception that we sell data to advertisers. We do not sell data to advertisers.” “What we allow is for advertisers to tell us who they want to reach, and then we do the placement … That’s a very fundamental part of how our model works and something that is often misunderstood.” Senator Tammy Baldwin asks whether the Cambridge University neuroscientist Aleksandr Kogan sold the Facebook data to anyone besides Cambridge Analytica? Zuckerberg: “Yes, he did.” “We’re investigating every single app that had access to a large amount of information in the past. And if we find that someone improperly used data, we’re going to ban them from Facebook and tell everyone affected.” Regulations “My position is not that there should be no regulation. “I think the real question, as the internet becomes more important in people’s lives, is what is the right regulation, not whether there should be or not.” Russian interference “One of my greatest regrets in running the company is that we were slow in identifying the Russian information operations in 2016. “We have kicked off an investigation … I imagine we’ll find some things. “There are people in Russia whose job it is to try to exploit our systems and other internet systems and other systems as well. “This is an ongoing arms race. As long as there are people sitting in Russia whose job is it to try to interfere in elections around the world, this is going to be an ongoing conflict.” Taking responsibility “It was my mistake, and I’m sorry. “I started Facebook, I run it, and I’m responsible for what happens here. “It’s clear now that we didn’t do enough to prevent these tools from being used for harm. That goes for fake news, foreign interference in elections, and hate speech, as well as developers and data privacy.”